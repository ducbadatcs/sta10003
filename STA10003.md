```table-of-contents

```

# Terminology:

- **Statistics:** used as an overarching term to include the procedures and techniques that are used to organize, summarize and interpret information collected

- within "Statistics" further terminology is used to represent such things as populations, samples, variables

- **Population:** the group all the things we care about (draw data from + conclude about)
  - **Parameter:** number of the population, usually written as $N$
- **Sample:** subset of a population, studied

  - Must be representative of the population if we want to infer/generalize our finding(s) to the population
  - usually taken at random from the population (random sampling)

- **Variable:** label of the element / feature we want to evaluate for everyone
  - must not be the same for everyone
  - Example:
    - Gender
    - Age
    - Time of Week

| Descriptive Statistics                                    | Inferential Statistics                                                                            |
| --------------------------------------------------------- | ------------------------------------------------------------------------------------------------- |
| Describe the features of sample/population                | Use sample to generalize to larger population                                                     |
| Present data in a purely factual way                      | Make estimates and predictions                                                                    |
| Present final result visually (table, charts, graphs)     | Present final result as probabilities                                                             |
| Draw conclusions based on known data                      | Draw conclusions beyond known data                                                                |
| Use measures like Central Tendency, Distribution, Variace | Use techniques like Hypothesis testing, confidence intervals, and regression-correlation analysis |

# Research

## Types of Research

| Descriptive Research                                              | Correlational Research                                                                            | Comparative Research                         |
| ----------------------------------------------------------------- | ------------------------------------------------------------------------------------------------- | -------------------------------------------- |
| Define characteristics of phenomenon without investigating causes | Explore relationship between different subjects and variables **without researcher manipuation.** | Compare 2 or more groups on the same measure |
| E.g. age of students studying something                           | Is there a relationship between $X$ and $Y$?                                                      | Is $X$ > $Y$?                                |

## Research Methods and Independent / Dependent variables

- **Experimental Method:** Use an Independent Variable $IV$ and a Dependent Variable $DV$, if a researcher **manipulates $IV$ and keeps all the other variables constant => $DV$ changes** (e.g. control medication between $0, \ 5, \ 10$ mg => pain reduction check), then we **can conclude that $IV$ causes a change in $DV$**
- **Non-experimental methods:**
  - **Observational / Correlational Research:** We **only observe $IV$ and $DV$, with the $IV$ free to wary with no casual conclusions. Often useful to taken first**
    - Is there a relationship between $IV$ - $DV$?
    - Is there a relationship between weight and height?
    - Information is not manipulated, only recorded
  - **Non-equivalent groups:**
    - Comparing $DV$ of different groups of $IV$ without changing the $IV$
    - Comparing heights of males and females
    - The $IV$ is **NOT** manipulated
  - **Pre-Post Studies:**
    - Measure the $DV$ at different times ($IV$ = time?)
    - Comparing scores $DV$ before and after completing competency training

Further information on [[#Independent and Dependent Variables]]

## Research designs

| **Independent groups design**           | **Repeated Measures Design**                                     | **Matched pairs design**                                         |
| --------------------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------- |
| Between-subjects design                 | Within-subject design                                            | Matched-subject Design                                           |
| $DV$ measured only once per participant | $DV$ measured on 2 different occasions on the same participants. | $DV$ measured on one occasion for carefully matched participants |
| $n$ = number of participants            | $n$ = number of participants (difference scores)                 | $n$ = number of matched pairs (different scores)                 |

# Variables

## Discrete vs Continuous: based on measure, not on values

- **Discrete:** separate, no value in between, "Countable" number of values. E.g. Number of children, number of test questions answered, etc
- **Continuous:** Infinite number of values that falls between 2 measured values, divisible into infinite number of fractional parts, e.g. age, time

## Measurement of Variables

- **Categorial**:
  - **Nominal:** used to **label** the group(s): $1$ = Male, $2$ = Female, $3$ = Other, $4$ = Prefer not to say
  - **Ordinal:** used to **Label AND Order**: $1$st, $2$nd, etc
- **Metric:**
  - **Interval:** used to **label AND order AND intervals between numbers are equal** e.g. temperature
  - **Ratio:** all conditions of Interval + **ZERO means absence of something** e.g. number of questions done in a test

## Independent, Dependent and Nuisance Variables

The $DV$ is also referred to as the **OUTCOME** or **RESPONSE** variable, while the $IV$ is referred to as the **PREDICTOR** or **EXPLANATORY** variable.

![[Pasted image 20250407230949.png]]

To differentiate between $IV$ and $DV$, look at how the statement / sentence is written:

![[Pasted image 20250407231031.png]]

To see if the research is Experimental or Observational, we do the following:

1. Identify the variables
2. Work out which is the $DV$ and which is the $IV$
3. Has the $IV$ been manipulated?
   - **If YES => Experimental**
   - **If NO => Observational**

### Nuisance Variables and Confounding Factors

Also see [[#Nuisance Variables (continued)]]

#### Definition

Nuisance Variables are **any variables other than the IV that may be associated with the DV.** They can become **confounding factors** if they are **associated with both the DV and IV** (alters the logic of the experiment).

Thus **in an experiment**, we **need to identify what other variables may have an effect on the $DV$ other than the $IV$**

(the $IV$ is **NEVER** a nuisance variable, and the nuisance variable must vary.)

![[Pasted image 20250408102820.png]]

#### Types

**Participant Nuisance Variables** are the **nuisance variables associated with the participant:** e.g. age, gender, experience

**Environmental Nuisance Variables** are the **nuisance variables associated with the conditions of the experiment:** e.g. type of car, driving course, time of day

#### Avoiding

To avoid confounding variables: we can

- **Randomize groups**
- **Experimental control:** **try to make the $IV$ the only variable that varies systematically, and keep variation in nuisance variables to a minimum**

# Statistical Notation

- **Population:** $N$ as parameter (number of scores in population)
  - **Population of Venezuela:** $N = 32674532$
- **Sample:** $n$ as size (number of scores in sample)
  - **Sample from population of Venezuela:** $n = 100000$
- **Raw scores:** $X$ (and $Y$ if measuring a second variable)
  - scores from the data collection
- **Summing scores:** $\Sigma$
  - $\Sigma X$ means adding up add all the $X$ value

# Order of operations

Essentially

1. **Anything in brackets is evaluated first**
2. **Squaring / Exponentiation is done second**
3. **Multiplication or division done third, from left to right**
4. **Summation $\sum$ is fourth**
5. **Any other addition / subtraction is the final step**

# Bias

## What is bias:

Bias is the **disproportionate amount** **in favor of** **or against** something, that makes results non-representative

2 main forms:

### Selection bias:

> **Selection bias** is the [bias](https://en.wikipedia.org/wiki/Bias "Bias") introduced by the selection of individuals, groups, or data for analysis in such a way that proper randomization is not achieved, thereby failing to ensure that the sample obtained is representative of the population intended to be analyzed

- Occurs when sample selected does not fully represent the population of interest
  - Can be resolved by random sampling

### Information Bias

> **Information bias** is a [cognitive bias](https://en.wikipedia.org/wiki/Cognitive_bias "Cognitive bias") to seek information when it does not affect action. An example of information bias is believing that the more information that can be acquired to make a decision, the better, even if that extra information is irrelevant for the decision.[[1]](https://en.wikipedia.org/wiki/Information_bias_\(psychology\)#cite_note-Vaughan2013-1)

Consider negative wording:

> "Every year since 1950 the number of American children gunned down has doubled"

which means that the number of American children killed by guns grow exponentially

compared to the correct statement

> "The number of American children killed each year by guns has doubled since 1950"

Information Bias may come from:

- Emotive Language
- Leading Question
- Double-barrelled Question
- Unclear Question
- Options of Answer
- Source of study

## Identifying Bias

- How were the individuals / objects of study chosen?
- What measurements were made?
- What questions were asked?
- Who conducted / sponsored the study?

## Avoiding Bias

- Sample should be randomly selected
- Non-leading language in question wording
- Source(s) should be reliable / credible
- **If there is any bias, we cannot conclude anything
  meaningful about the population of interest from
  looking at the sample!**

> - **IF** the sample has been selected in an unbiased way, **AND** the measurements / questions are unbiased, **THEN** we can use our sample to tell us something about a population.
> - **IF** either the sample selection or the measurements are biased **THEN** the sample doesn’t tell us **ANYTHING** meaningful about a population.
> - An unbiased sample could be used to tell us something about a **different** population.

# Frequency Distributions

Frequency Distributions is a way of organizing values in to categories / intervals

- Provides an **organized picture** of the data
- Presented in either **tabular or graphical** form.

## Ungrouped Frequency Table

Each category / distinct value has its frequency recorded in a table:

- First column lists categories / intervals $X$
- Second column lists the frequencies $f$
- Additional columns are sometimes included:
  - Sum of frequencies $\sum f = n$ (number of cases)
  - $\sum fX$ column (total number of frequency \* number of appearance)
  - Proportion $p = \frac{\text{Frequency}}{\text{Total Number}}$

![[Pasted image 20250406215604.png]]

## Grouped Frequency Table

- Each interval has its frequency recorded
  - Width should be a simple number (integer?)
  - Lower score in each interval should be multiple of width
  - No gaps or overlapping values

![[Pasted image 20250406215539.png]]

## Proportion + Levels of Measurement of Variables

$$
\text{Proportion}(p) = \frac{\text{Frequency}}{\text{Total number}}
$$

Level of measurement of variables:

- **Metric variables** are those that can be measured or counted reasonably accurately (e.g. height)
- **Categorial variables** are those can be classified by putting into groups (e.g. gender)
- We can put certain variables in both types depending on how we look at them (e.g. Income can be measured as a number or low/medium/height)

# SPSS Output: Categorical and Metric variables

## Categorical

SPSS **uses number to code categorical variables**, the values are arbitary, whilst metric means something real

![[Pasted image 20250406220042.png]]

Use the **Frequency procedure** to obtain output for categorical variables

![[Pasted image 20250406220152.png]]

The graphical representation for Categorical Variables is called the Bar Chart (also called Bar Graph)

![[Pasted image 20250406220330.png]]

## Metric

We use the **Explore** procedure to obtain output for **Metric** variables

![[Pasted image 20250406224912.png]]

![[Pasted image 20250406220434.png]]

_Box plot_

The graphical representation for Metric Variables in reports is the Histogram

![[Pasted image 20250406220459.png]]

## Other types of Frequency Graph

In a **Frequency Polygon**, a dot is placed above the center of each score. The "height" of the dot ($y$-coordinate) corresponds to the frequency, a line is drawn from dot to dot to connect the series. The graph is finished by drawing a line down to the $X$- axis at each end of the range of

![[Pasted image 20250406221119.png]]

## Which analysis / procedure?

- **For categorical data:**
  - **Frequencies procedure**
  - Request **Bar Chart / Bar Graph**
- **Metric data**
  - **Explore procedure**
  - Default for box plot
  - Request **percentiles table**
  - Request **histogram**

# Graphs for Population distributions

Proportions are usually used in histograms and other graphs when representing data for a whole **population**

- Smooth curves are also used in representing distributions in cases where the data is metric

![[Pasted image 20250406221600.png]]

# Features of Distributions of Metric Data

- **Central Tendency:** A single score that defines the "center" of the distribution (mean/median/mode): The value that is "Most typical" / "Most representative" of the group
- **Variability:** Measures the degree to which scores are spread out / clustered together (standard deviation / IQR)
- **Shape:** Symmetric / Positive skewed / Negative skewed
- **Extreme scores / outliers:** Extremely high / low values, extreme and unusual values

## Central Tendency

### The Mean

#### Calculation of the mean

- **Population mean:**
  $$
  \mu = \frac{\sum X}{N}
  $$
  where
- $\mu$ is the mean of the population
- $\sum$ means "sum of"
- $X$ represent a value
- $N$ is the number of values

- **Sample mean:**

  $$
  M = \frac{\sum X}{n}
  $$

- $M$ represents mean of the sample
- $\sum$ means "sum of"
- $X$ represent a value
- $n$ is the number of values

In other words, generalized:

$$
\text{Mean} = \frac{\text{Sum of data values}}{\text{Number of data values}}
$$

```python
def mean(x: list[float]) -> float:
	return sum(x) / len(x)
```

#### Interpretation

The mean is the amount that **each individual receives** when the total is **divided equally among all individuals** in the distribution

#### Characteristics

- Every score adds to the total $\sum X$ and contributes one point to the number of scores $n$
- Change any value of the score changes the mean
- Adding a new score or removing one changes the mean, unless the added/removed one is equal to the mean
- If a constant is added to / subtracted from every score, that same constant will be added to / subtracted from the mean
- If every score is multiplied or divided by a constant, the mean will also be multiplied / divided by that constant.

### The Median

#### Calculation of the median

- Order the data from highest to lowest
- If there are an **odd** number of values, return the middle value
- If there are an **even** number of values, return the average of the middle 2 values

```python
def median(x: list[float]) -> float:
	x.sort()
	if len(x) % 2 == 1:
		return x[len(x) // 2]
	else:
		return (x[len(x) // 2 - 1] + x[len(x) // 2]) / 2
```

#### Characteristics

The median is the midpoint in the distribution. It divides the distribution into 2 equal parts: half are greater than or equal to the median, half are lower than or equal to the median

### The Mode

#### Calculation of the mode

- The mode is the score/category that has the greatest frequency.

#### Characteristics

- It can be an useful measure of central tendency as it corresponds to an actual score in the data. **The mean and median are calculated and often produce an answer NOT equal to any score in the distribution**
- A distribution will have only **one mean and one median**, but can have multiple modes

  - A distribution with 2 modes is called a **bimodal distribution**, and with > 2 modes is called **multimodal**

- Used as the appropriate measure of central tendency for categorical data, only measured for nominal scale. (also can be used for ordinal but median is more so, idk)

### Comparing the mean and median

- The mean can be the "balance point" because $$\sum \text{distance above the mean} = \sum \text{distance below the mean}$$
- The median defines the middle in terms of **scores**
- If a distribution is reasonably symmetric, the values of the mean and median are relatively similar
- If a distribution is skewed, the mean will be pulled in the direction of the skewe. It will also be affected by outliers

=> The **mean is the most appropriate** for **reasonably symmetric distributions** with **no outliers**
=> The **median is most appropriate** for **skewed distributions**,
or **distributions with outliers**

![[Pasted image 20250406233507.png]]

![[Pasted image 20250406233534.png]]

## Shape of distributions

### Symmetric

**Left and right are roughly mirror** sides of each other. The median (midpoint) is at the center, the mean (balance point) is also at the center. If the distribution has only one mode, it will also be in the center of the distribution

![[Pasted image 20250406222026.png]]

### Skewed

- Scores Taper off at one end
- Tail indicates direction of the skew

In **skewed distributtions**, especially skewed distributions for continuous variables, the mean, median and move are in different places.

- **Positively skewed** => mode < median < mean
- **Negative skewed** => mean < median < mode

![[Pasted image 20250406224757.png]]

## Variability

Measures the degree to which scores are spread out / clustered together

- **How different** are the scores?
- Are the scores **spread out or closely clustered** together?
- Distance between scores

=> Provides information about the **amount of error** we
can expect between a sample and a population

### The main measures of variability

- **Range**
- **Variance**
- **Standard Deviation**

#### Range

Range is defined to be largest score - smallest score

$$
\text{Range} = X_\text{max} - X_\text{min}
$$

```python
def range(x: list[float]) -> float:
	return max(x) - min(x)
```

**NOT** a reliable measure of variability, due to outliers

#### Variance and Standard Deviation

**The Variance** is the mean of squared deviations

**The Standard Deviation** is the **most commonly used** measure of variability, using the **mean** as a starting / reference point. It measures the variability between each score and the mean, e.g. how much each score deviates from the mean.

##### For populations

###### Deviations for population

The variance and standard deviation for populations is calculated using **deviations**. The deviation of a score $X$ in a population with mean $\mu$ is $X - \mu$

###### Calculation of the Standard Deviation for populations

The variance and standard deviation for populations is calculated using the **sum of squared deviations**. The **sum of squared deviations** $\text{SS}$ has two formulas (due to float issues)

- **Definitional Formula: (calculated via deviations scores):** $$\text{SS} = \sum (X - \mu)^2$$ Can be prone to rounding and errors
- **Computational formula (calculated via actual scores):** $$\text{SS} = \sum X^2 - \frac{(\sum X)^2}{N}$$ minimizing error due to complexity

Then the **population variance** $\sigma^2$ is calculated by

$$\sigma^2 = \frac{\text{SS}}{N}$$

and the **population standard deviation** $\sigma$ is calculated by

$$\sigma = \sqrt{\sigma^2}$$

##### For samples

> **Samples are usually less variable than populations**

Sample variability gives a **biased estimation of the population variability**, and can **overestimate/underestimate** variability. Therefore, we use a slightly different formula.

###### Deviations for samples

The variance and standard deviation for a sample is calculated using **deviations**. The deviation of a score $X$ in a sample with mean $M$ is $X - M$

###### Calculation of the Standard Deviation for samples

The variance and standard deviation for populations is calculated using the **sum of squared deviations**. The **sum of squared deviations** $\text{SS}$ has two formulas (due to float issues)

- **Definitional Formula: (calculated via deviations scores):** $$\text{SS} = \sum (X - M)^2$$ Can be prone to rounding and errors
- **Computational formula (calculated via actual scores):** $$\text{SS} = \sum X^2 - \frac{(\sum X)^2}{n}$$ minimizing error due to complexity

Then the **sample variance** $s^2$ is calculated by

$$s^2 = \frac{\text{SS}}{n - 1}$$

and the **sample standard deviation** $s$ is calculated by

$$s = \sqrt{s^2}$$

###### Why $n - 1$ instead of $n$ ?

Each sample taken may have a different mean than the population. Variance tells how varied these samples may be, but values will cluster around the mean. To compensate for samples being less variable than the population, we use $n - 1$ in calculations, which introduces the **degree of freedom**

$$
\text{df} = n - 1
$$

which means that for $n$ scores, $n - 1$ is allowed to vary, the remaining one is fixed

##### Variance and Standard Deviation in SPSS

Use the **Explore procedure**

![[Pasted image 20250407112257.png]]

###### Important Note:

Note that **SPSS cannot differentiate between a sample
and a population, it automatically usees the $n - 1$ adjustment for samples to calculate the Variance and Standard Deviation.**

If the scores are actually populations, the **population standard deviation** can be obtained from the **sample standard deviation** via:

$$
\sigma = s \sqrt{\frac{n - 1}{n}}
$$

##### Additional Information

- Adding a constant score to each value **does not change the variance / standard deviation**, it just moves the distribution.
- Multiplying each score by a constant **DOES change** the standard deviation by the same multiplier
- If the mean is used as the measure of center, the standard deviation should also be shown $(\mu = \dots, \ \sigma = \dots)$
-

# Percentiles and Percentiles Ranks

## Definition

The location of individual scores within a distribution can be described by percentiles and percentile ranks.

When a score is described by its percentile rank, it is called a percentile. **A $p$-th percentile has $p\%$ of values in the distribution or below it.**

e.g. IQ score of $85\%$ is the $16$th percentile -> There are $16\%$ of people with an IQ <= 85 / IQ score of 85 has a percentile rank of $16\%$

Percentiles and Ranks can be calculated by counting number of scores that are in or below each category on the scale

![[Pasted image 20250407013751.png]]

## SPSS Table

![[Pasted image 20250407013822.png]]

A few special marks

| Percentile | Name    |
| ---------- | ------- |
| $0\%$      | Minimum |
| $25\%$     | Q1      |
| $50\%$     | Median  |
| $75\%$     | Q3      |
| $100\%$    | Maximum |

![[Pasted image 20250407013956.png]]

![[Pasted image 20250407014017.png]]

# Reporting on a distribution

## Categorical

Include the following:

- **Information about variable**
- **Sample and Sample Size**
- **Information that we found out**
- **Other information of interest**

> The distribution of ‘most common use of wearable technology’ is
> shown in Figure 1. In this sample of 65 STA10003 students, $55.4\%$
> reported that they check their step counter first. A similar
> percentage of students checked either their active minutes ($16.9\%$) ,
> or ‘other’ activities $15.4\%$. The remaining students suggested they
> checked their heart rate in the first instance ($12.3\%$).

![[Pasted image 20250407130052.png]]

## Metric

Include labelled histogram and the following information:

- **Shape:** symmetric, positively skewed, negatively skewed
- **Centre:**
  - **Symmetric with no outliers** -> include mean and Standard Deviation
  - **Skewed or symmetric with outliers** -> include median
- **Spread:** Use the "typical" (**middle $50\%$ (IQR) from Percentiles table**), use $25$ -th and $75$ -th percentiles
- **Outliers:** Extreme values, state figure and direction

> The distribution of Life Expectancy in years for a random sample of 388 Australian males is displayed in Figure 2. The distribution is approximately symmetric, and the average life expectancy was 78.02 years ($s$ = $4.75$ years). Typically, age at time of death was between $74.56$ and $80.91$ years, with half of the life expectancy values falling within this range.

![[Pasted image 20250407131132.png]]

![[Pasted image 20250407131116.png]]

![[Pasted image 20250407131045.png]]

# z-score

An **individual score** $X$ in a distribution is often referred to as a **raw score.** We are also interested in the relative positions of a score in a distribution.

A **z-score** provides us with a measure to determine how many standard deviations **above** or **below** the mean the value is.

## Calculation

### For population

For a score $X$ in a population with population mean $\mu$ and population standard deviation $\sigma$:

$$
z = \frac{X - \mu}{\sigma}
$$

### For sample

For a score $X$ in a population with sample mean $M$ and sample standard deviation $s$:

$$
z = \frac{X - M}{s}
$$

### Calculating raw score from Z-score

Knowing the formula, we can rewrite a raw score $X$ via the z-score in a population using the population mean $\mu$ and the standard deviation $\sigma$ as:

$$
X = \mu + \sigma z
$$

and for a sample with sample mean $M$ and sample standard deviation $s$ as:

$$
X = M + sz
$$

## Standardization of a distribution via z-score

If every $X$ value in a distribution is transformed into a z-score, the result is a distribution with shape identical to the shape of the original distribution, and the mean $\mu$ will always equal $0$ , the standard deviation $\sigma$ will always be equal to $1$

When a **normal distributio**n is standardized like this, it is called the **standard normal distribution**

## Comparison using z-scores

We can compare 2 results from 2 distributions using z-scores. This requires knowing the mean / standard deviation of each distribution.

- **Higher z-score => better**
- **Lower z-score => worse**

# Probability and Random Sampling

## Probability

The probability of an event occuring is the chance / likelyhood that the event occurs. It can be expressed as a proportion (real number between $0$ and $1$) or an percentage (between $0\%$ and $100\%$ )

$$
\text{Probability of event A} = \frac{\text{Number of outcomes classified as A}}{\text{Total number of possible outcomes}}
$$

## Random sampling

**In order to draw an independent sample for most statistical applications, need to draw an independent sample**

- **Sample random sample:** each member of the population has an equal chance of being selected
- **Independent random sample:** Each member of the population has an equal chance of being selected **AND the probability of being selected stays constant from one selection to the next (if more than one individual is selected)**

> E.g. there are $52$ cards in a deck of playing cards.
> => Probability of choosing any card: $\frac{1}{52}$
> in which case for a given card we have chosen it, or we haven't. If the card wasn't the one we had chosen, we have to return it to deck. Otherwise the probability of choosing the chosen card becomes $\frac{1}{51}$ which is inconsistent.

## $68 - 95 - 99.7$ rule

The rule corresponds to the fact that:

- One standard deviation from either side of the mean captures approximately $68\%$ of data
- Two standard deviations from either side of the mean captures approximately $95\%$ of data
- Three standard deviations from either side of the mean captures approximately $99.7\%$ of data

![[Pasted image 20250407125715.png]]

> [!Note] A mathematical explanation
>
> The rule can be explained using integrals of the $\text{erf}(x)$ function.
> We seek to evaluate $P(\mu - n\sigma \leq x \leq \mu + n\sigma)$ for a population with mean $\mu$ and standard deviation $\sigma$ . We have:
> $$P(\mu - n\sigma \leq x \leq \mu + n\sigma) = \int_{\mu - n\sigma}^{\mu + n\sigma} \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{1}{2} \left(\frac{x - \mu}{\sigma}\right)^2}$$
> Using the change of variable to the z-score above:
> $$P(-n \leq z \leq n) = \int_{-n}^{n} e ^ {-\frac{z^2}{2}}$$
> which calculating the integral for $n = 1, \ 2, \ 3$ reveal the cases.

We can use the same way to calculate probability in a normal distribution, by turning into z-scores. In a normal distribution $95\%$ of the data is $1.96$ standard deviations either side of the mean $(-1.96 \leq z  \leq 1.96)$

# Sampling Distribution and the Central Limit Theorem

Using z-scores, we are able to describe the location of a score in a distribution. But z-score and probabilities only contain information about a single score.

While z-scores are also useful for determining where **sample statistics** falls within a distribution, but samples provide an incomplete picture of the population.

Thus we ask an important question:

> Is the sample truly representative of the population?

If we take multiple samples, they **may differ slightly on means, standard deviations, etc**. This difference is called the **sa,pling variability.** If we take a lot of samples, we can build a picture of the samples called a **sampling distribution.**

## Distribution of sample means

The distribution of sample means is **ALL possible random samples of size $n$ obtained from a population.**

- Its population would therefore be covered entirely with samples.
- All samples are needed to calculate probability.
- Each sample is different, thus we need to be aware of the **samping error**, the "natural" discrepancy between sample statistics and population parameters.

=> Thus we need a method to make a decision on which sample truly represents the population.

- The sample means should cluster around the population mean, and should form a normal distribution.

**The larger the sample size, the narrower the distribution, and the closer the sample mean should be to the population mean**. When we have larger populations / samples, calculations can become cumbersome, as we are using all possible samples (and if we can actually obtain all possible samples)

To avoid having to take multiple samples, we use the **Central Limit Theorem**

## Probability and the Distribution of Sample Means

Standardizing the Distribution of Sample Means allows us to calculate the probability associated with any specific sample. We once again use the z-score.

The z-score here gives the **location of a sample mean in relation to all other possible sample means:**

- **Positive z-score:** above the mean
- **Negative z-score:** below the mean

It is calculated by:

$$
z = \frac{M - \mu_M}{\sigma_M}
$$

where

- $M$ is the sample mean
- $\mu_M$ is the population mean
- $\sigma_M$ is the standard error

> E.g. IQ scores for a population of university students is normally distributed: $\mu = 100, \ \sigma = 15$ . What is the z-score of a sample mean $M = 104$ taken for $n = 25$ students?
> $$\sigma_M = \frac{\sigma}{\sqrt{n}} = \frac{15}{\sqrt{25}} = 3$$ > $$z = \frac{M - \mu}{\sigma_M} = \frac{104 - 100}{3} = \frac{4}{3}$$

The primary use of the Distribution of Sample Means is to **calculate the probability associated with any specific sample**. Thus, **probability is equivalent to proportion**, because the distribution of sample means represents the entire set of all possible sample means.

## Sampling distribution for Proportions

We **apply the same theory to categorical data**.

- **Sampling distribution proportion equals population proportion**
- **The standard deviation of the samples (standard error) depend on sample size**

## Standard error calculation for sample proportions

The **standard deviation of the sampling distribution (standard error)** depends on the size of the sample:

$$
\sigma_\hat{p} = \sqrt{\frac{p(1-p)}{n}}
$$

where

- $\sigma_\hat{p}$ is the **standard error (standard deviation of the sampling distribution)**
- $p$ is the **population proportion**
- $n$ is the **size of the sample**

## Central Limit Theorem (summary for both variable types )

- **Shape: if the samples are taken from a normally distributed population, they should also be normally distributed.**

  - **For sample means (Metric):** Regardless of the shape of the original distribution, **if the sample size is sufficiently large $(n \geq 30)$**, then the sampling distribution is **almost "perfectly normal".**
  - **For sample proportions (Categorical):** if $np \geq 10$ and $n(1 - p) \geq 10$ the sampling distribution is approximately normal

- **Central Tendency:**

  - \***\*For sample means (Metric)** The mean of all sample equals the mean of the population $\mu_M = \mu$
  - **For sample proportions (Categorical):** The mean of the sample proportion equals the population proportion $\mu_\hat{p} = p$

- **Variability: **The standard deviation of the samples (standard error)\*\* depends on the size of the samples $n$ :
  - For **For sample means (Metric)** $$\sigma_M = \frac{\sigma}{\sqrt{n}}$$
  - For **For sample proportions (Categorical):** $$\sigma_\hat{p} = \sqrt{\frac{p(1 - p)}{n}}$$

## Example

> The drug company claims that **$30\%$ of people aged between 18 and 30 years get a measles vaccination.** A
>
> A random sample of $40$ people aged between $18$ and $30$ years is taken and $6$ are found to have been vaccinated

> => proportion for sample = $\frac{6}{40} = 15\%$
>
> **Central tendency: Mean of sample proportions equal population proportion:** $$\mu_\hat{p} = 0.30$$
> Normal distribution check: $np = 40 \times 0.3 = 12 > 10$ and $n(1-p) = 40 \times (1 - 0.30) = 28 > 10$ therefore the distribution is normal.
>
> **Variability: the standard error depends on the size of the samples** $$\sigma_\hat{p} = \sqrt{\frac{p(1-p)}{n}} = \sqrt{\frac{0.30 \times (1 - 0.30)}{40}} = 0.07$$

When the distribution of sample proportions is normally distributed, $95\%$ of the sample proportions will lie within $1.96$ standard errors of the population proportion. Any sample proportion(s) that lie **outside** this range are considered to be **unusual or unlikely** as they are in the $5\%$ of values in the sampling distribution that are the most **extreme** (critical region)

=> **Conclusion:** if there has been no bias, then the sample was **NOT** drawn from the population in mind, or the population proportion of people aged between 18 and 30 who are vaccinated is different than 0.30, it is something LESS than 0.30.

## Summary

- **A sample will not provide us with a perfectly accurate picture of the population**

  - There is **always a discrepancy between sample statistic and population parameter**
  - Some samples have **small discrepancies**, others have **large discrepancies**

- The **standard error provides a measure of the discrepancy**

  - It measures **the average distance between sample mean and population mean** (or **sample proportion and population proportion**)

- When the sampling distribution is **approximately normal:**
  - $95\%$ of sample means / sample proportions will **lie within $1.96$ standard errors of the population mean / proportion**
  - 5% of the sample means / sample proportions will **lie beyond $1.96$ standard errors of the population mean / population proportion** (the critical region)

# Hypothesis testing

![[Pasted image 20250408150848.png]]

## Inferential Statistics:

A hypothesis test provides us with a statistical method so we can use our **sample findings** to make a conclusion about a population. The aim is to rule out chance (sampling error) as an explanation.

Steps in the general process:

1. **State hypothesis**, what we think is happening
2. Use this hypothesis to **predict characteristics the sample should have**, **including the critical region**
3. **Obtain a sample** and calculate the **sample statistics.**
4. **Compare the sample data findings to the hypothesis** to reach a conclusion.

## Steps of Hypothesis Testing

### Step 1: State Hypothesis

We use the **Null Hypothesis $H_0$ **, the idea that **the change / difference / relationship / effect being studied does not exist**, and the **Alternate Hypothesis $H_1$** (the research hypothesis) **that the change / difference / relationship / effect DOES exist**

### Step 2: Predict Characteristics

If the **Null Hypothesis** is correct we **predict the characteristics the sample should have**, **including the critical region**:

- **Directional / Non-Directional**
- We use the alpha level $\alpha$ to decide the critical region (which is unlikely to occur if the null hypothesis is true) and the convention level of $\alpha = 0.05$ to make a decision about the Null Hypothesis.
- **The critical region for $\alpha = 0.05$ is $-1.96 \leq z  \leq 1.96$ boundaries**
  - if z-score shows an extreme value (value in critical region) than we reject $H_0$ (evidence to suggest that the research hypothesis is correct)
  - if z-score not in critical region, we do not reject $H_0$ (no evidence to suggest the hypothesis is correct)
- We use the probability value p-value $p$ (chance out of 1000 to obtain result)
  - **$p < 0.05$:** **significant**, **reject** $H_0$
  - **$p \geq 0.05$:** **NOT significant**, \*\*NOT rejecting $H_0$

![[Pasted image 20250407190449.png]]

![[Pasted image 20250407190631.png]]

### Step 3: Obtain sample

**Obtain a sample from the population** an **calculate the sample statistic (one sample z-test)**

The z-test statistic (z-score) is a standardized value which allows us to compare the **difference between the sample mean and hypothesized population mean**

$$
z = \frac{M - \mu}{\sigma_M}
$$

where

- $M$ is the mean of the sample
- $\mu$ is the hypothesized population mean (based on the Null Hypothesis)
- $\sigma_M$ is the standard error

### Step 4: Compare the data findings to the hypothesis.

Is the sufficient evidence to convince us...

- **If z-score is NOT within critical region:** no evidence to suggest to alternate hypothesis $H_1$ is correct, **do NOT reject $H_0$**
- **If z-score is within the critical region (extreme value):** evidence to suggest that the alternate hypothesis $H_1$ is correct, \*\*reject $H_0$
- \*\*
  ![[Pasted image 20250407194447.png]]

## Example

> It is known that the general adult population IQ is normally distributed with mean $\mu = 100$ with standard deviation $\sigma = 15$. We define the Null Hypothesis $H_0$ that the average IQ of university students is **NOT DIFFERENT** compared to that of the general adult population, and the Alternate Hypothesis $H_1$ that there is a difference between the IQ of university students and the general adult population.
>
> Supposed we have a random sample of $n = 25$ university students and found their mean IQ was $M = 112$. What can we conclude?

> We calculate the standard error: $$\sigma_M = \frac{\sigma}{\sqrt{n}} = \frac{15}{\sqrt{25}} = 3$$
> and the z-statistic:$$z = \frac{M - \mu}{\sigma_M} = \frac{112 - 100}{3} = 4$$

> thus $z$ lies in the critical region, and we conclude that **there is evidence to suggest that average IQ of university students is different from that of the general adult population**

![[Pasted image 20250407200011.png]]

via the SPSS output, we can see that the sample mean is $4$ standard errors above the population mean.

> If the true average student IQ really was 100, would we be likely to get a random sample of 25 students with an average IQ as extreme as 112?

No, because our sample was more than 1.96 standard errors above the mean of the sampling distribution

> What can we conclude from this?

The average IQ of university students is higher than that of the general population

## Uncertainty and Errors

Hypothesis testing is an inferential process, based on limited information to reach a conclusion.

- We use samples, which **provides limited / incomplete information about the population, and yet a hypothesis test uses a sample to draw a conclusion about the population**. Thus, there is a possibility that we made an incorrect decision, which led to 2 types of errors: **Type I** and **Type II** errors.

![[Pasted image 20250407201152.png]]

### Type I (False positive)

A **type I error happens when a researcher reject a null hypothesis that is actually true** (conclude that there is an effect / relationship / difference / etc when there is no such thing).

It happens when a researcher unknowingly obtained an extreme, non-representative sample.

- thus the hypothesis test is **structured to minimize the risk of this occurring**.
- The **alpha level** for a hypothesis test is **the probability that the test leads to a Type I error.** (it determines the probability of obtaining sample data in the critical region even though the Null Hypothesis was true)

### Type II (False Negative)

A **type II error happens when a researcher fails to reject a null hypothesis that is actually false** (e.g. concluding that there is no effect / relationship / difference / etc when there is actually one.)

It happens when the sample mean is not in the critical region even though there is an effect / difference / relationship

- Usually happens when the **effect / difference is small.**
- **The consequences of a type II error are not as serious as a type I error** (it shows that the means do not show the results expected by the researcher)

## Selecting an alpha level

The **main concern of selecting an alpha level** is to **minimize the risk of a type I error.**

- Alpha levels **tend to be very small probability values**, **convention is that the largest permissible value is $\alpha = 0.05$**

As the alpha level lowers, the hypothesis test demands more evidence and the **risk of making a type II error increases**

## p-values

We can also use p-values to make a decision instead of the z-values above. We use sample findings to make inference about a population.

The p-value is the **probability that our test statistic takes the observed value or a value more extreme** (based on the Null Hypothesis). The smaller the p-value the stronger the evidence / support for our finding.

**Always leave the p-value in 3 decimal places!** (represent chances in 1000)

SPSS conveniently provides us with p-values that we can use to compare to the significance level $(\alpha = 0.05)$

> A reminder that a NOT significant finding doesn’t mean that there ISN’T a change. There could be … the true population mean/proportion could be higher, lower or the same – we just don’t have the evidence from our sample.

## Hypothesis testing - Summary

![[Pasted image 20250408230936.png]]

- For scenarios involving **ONE VARIABLE**
  - **Metric:** Compare mean from sample to a **reference value**
    - **One sample t-test** if population standard deviation $\sigma$ known
    - **One-sample z-test** if population standard deviation $\sigma$ unknown
  - **Categorical:** Compare the proportion from our sample with a **reference proportion**
    - **Binomial test**
- For scenarios involving **TWO VARIABLES**
  - **Both Metric:**
    - **Correlation / Regression** if testing for relationship
    - **Paired samples t-test** if testing for difference (Repeated Measures / Matched pairs design)
  - **One Metric (DV), One Categorical (IV):**
    - **Independent samples t-test** compare means of the $DV$ between the two $IV$ groups
  - **Both categorical:**
    - **Crosstabs / Chi-square** if test for relationship

# t-statistic and t-tests

## Introduction and Calculation

A z-test can be used if we both know the population mean $\mu$ and the population standard deviation $\sigma$, but it is rarely the case that we know the $\sigma$. **If we do NOT know the population standard deviation $\sigma$, we can use a t-test.**

- A t-test uses the sample standard deviation $s$ or the sample variance $s^2$ so that we can use a single sample to make our predictions.
- To calculate the sample standard deviation, we use the equation $$s = \sqrt{\frac{\text{SS}}{n-1}}$$

When calculating the t-statistic, we use the **estimated standard error of the sample $s_m$**

$$
s_m = \frac{s}{\sqrt{n}}
$$

where

- $s_m$ is the estimated standard error of the sample
- $s$ is the sample standard deviation
- $n$ is the sample size

We then calculate the t-statistic as

$$
t = \frac{M - \mu}{s_m}
$$

where

- $t$ is the t-statstic (equivalent of z-score for unknown population standard deviation?)
- $M$ is the sample mean
- $\mu$ is the population mean
- $s_m$ is the estimated standard error

## The t-distribution

The t-distribution is **all of the t-values computed for every possible random sample of size $n = ?$ OR the specific degrees of freedom $\text{df} = n - 1$.** It has a **similar shape to a normal distribution, but more spread out, due to variation caused by using the sample mean $s$ to approximate the population standard deviation $\sigma$**

The shape of the distribution **alters with the degrees of freedom $\text{df}$** (the number of scores within the sample that are ‘free to vary’ independent of one another $\text{df} = (n – 1)$)

- **The larger the sample size, the narrower the distribution**
- **The smaller the sample size, the wider the distribution**

![[Pasted image 20250407203125.png]]

## Probabilities for the t-distribution

We use the **Unit Normal Table to locate proportions of the t-statistic** (just like z-test scores). We use critical values from the t-distribution table to compare to the t-statistic from the sample

After the test, we check the t-value:

- **If it is in the critical region, we reject the Null Hypothesis**
- **Otherwise, we fail to reject the Null Hypothesis**

We can use SPSS to conduct a One-sample t-test (cause we're lazy in this course lol what do you expect)

## The One-Sample t-test

![[Pasted image 20250407211234.png]]

### Assumptions of the One-sample t-test:

The One-sample t-test is underpinned by the following assumptions:

- **Independence of observations:** Each observation / score must be independent from any other, this is usually satisfied if a random sample is selected.
- **Population must be normally distributed:** Critical values / tables for the t-distributions / t-statistics are **mathematically based on a normal distribution**. In practical terms, violating this assumption has little effect especially when the sample size is sufficiently large.

### The test

Instead of using critical t-values, we use the p-value. The p-value is the **probability that our test statistic would take the observed value or a value more extreme, if the null hypothesis is true.**

- The smaller the p-value the stronger the evidence against the null hypothesis
- If a p-value is **less than the alpha test level $\alpha = 0.05$** we **reject the Null Hypothesis**

Steps in general:

1. **State the hypothesis** (Null hypothesis, Alternate Hypothesis) and the **alpha test level**
2. Use **SPSS** to produce **the one-sample t-test**
3. Obtain **the t-statistic, degrees of freedom and the p-value**ư
4. Make a decision about the Null Hypothesis based on whether or not the **p-value is less than the alpha test value** then form a conclusion.

To generate a one-sample t-test, we use the functions **Analyze > Compare Means > One-sample t-test**

![[Pasted image 20250407204822.png]]

![[Pasted image 20250407204838.png]]

SPSS also provides us with **95% Confidence Interval of the difference figures.** This provides us with **the boundaries for the difference between which our population mean may lie based on our sample findings**

![[Pasted image 20250407205419.png]]

### The $95\%$ confidence interval

The 95% confidence interval can also be calculated by hand:

$$
\mu = [M - t_\text{crit}s_m, \ M + t_\text{crit}s_m]
$$

where

- $\mu$ are the bounds of the interval (lower, upper)
- $t_\text{crit}$ is the critical region of the t-distribution
- $s_m$ is the estimated standard error of sample

### Example

> It is known that for the general adult population, IQ scores are normally distributed with mean $\mu = 100$ . We obtain a sample of $n = 25$ university of students with mean IQ $M = 112$ and standard deviation $s = 15.45$

We define the hypotheses with alpha level $\alpha = 0.05$

> $H_0$: The average IQ of university of students is **NOT DIFFERENT** to that of the general adult population
> $H_1:$ The average IQ of university of students is **DIFFERENT** to that of the general adult population

We obtain a sample with $n = 25 \Rightarrow \text{df} = n - 1 = 24$. This is a two-tailed test with $\text{df} = 24$ , the critical region will be all t-values outside the range $[-2.064, \ 2.064]$

We evaluate the estimated standard error $s_M$:

$$
s_M = \frac{s}{\sqrt{n}} = \frac{15.45}{\sqrt{25}} = \frac{15.45}{5} = 3.09
$$

And the t-statistic

$$
t = \frac{M - \mu}{s_M} = \frac{112 - 100}{3.09} \approx 3.8834 > 2.064
$$

Thus $t$ is in the critical region, **WE REJECT $H_0$**

**Conclusion: The average IQ of university students is different (higher) to that of the general population.**

### Writing a report

We write the report via the following:

1. Introduction, **including what we hypothesize** $(H_1)$
2. **Sample findings** (mean $M$ , standard deviation $s$ , sample size $n$ ) **including comparisons to our reference value**
3. Interpret the results of the hypothesis test, **include an interpretation of the 95% confidence interval**
4. **Conclusion based on sample finding** and **referring to the hypothesis**

#### Example 1

Example data and report:

> It was hypothesized that, on average, the IQ of university students differs to that of the general population.

> $H_0$: the IQ of the university students is equal to that of the general population
> $H_1$: the IQ of the university students is different from that of the general population

![[Pasted image 20250407205937.png]]

> It was hypothesised that, on average, the IQ of university students differs to that of the general population.
>
> In a random sample of 25 University students, the average IQ was $112.00$ $s=15.45$. This is higher than for the general population $100.00$.
>
> A one-sample t-test shows that the difference in the average IQ is significant, $t(24)=3.88, p<0.001$. The $95\%$ confidence interval indicates that, on average, for university students IQ is between $5.62$ points and $18.38$ points higher than for the general population.
>
> As expected, the IQ of university students does differ to that of the general population. The IQ of university students is higher than for the general population.

#### Example 2

> Ambulance Victoria recently announced that the inner city area of Yarra provided outstanding service to residents who required urgent medical services. In the city of Yarra, for the previous quarter, the ambulance response time to arrive at the scene was, on average, 8.5 minutes from the time of the ‘000’ call. The council members of a neighbouring area Yarburn believe that their response times were actually quicker than in Yarra, so they decide to test this. They took a random sample of records held at the local ambulance station, and noted the response times for each emergency call over the same time period.

> $H_0$: Ambulance response time in Yarburn is slower than or equal to $8.5$ minutes
> $H_1$ Ambulance response time in Yarburn is faster than $8.5$ minutes

![[Pasted image 20250407210600.png]]

> It was hypothesised that, on average, the ambulance response
> time in Yarburn is less than in the inner city of Yarra. In a
> random sample of $30$ Yarburn ambulance response times, the
> average response time was 8.77 minutes $s=1.71$ minutes. This
> is higher than the ambulance response time in the inner city
> area of Yarra $8.50$ minutes. A one-sample t-test shows that the
> difference in the average ambulance response time is not
> significant, $t(29)=0.88, \ p=0.388$ . The $95\%$ confidence interval
> indicates that in Yarburn the average ambulance response time
> is between $0.36$ minutes less, and $0.91$ minutes more than for
> the inner city area of Yarra. There is insufficient evidence to
> suggest that, on average, the ambulance response time in
> Yarburn is less than in the inner city of Yarra.

## The Binomial test

### Assumptions of the Binomial Test:

We satisfy the conditions $np \geq 10$ and $n(1-p) \geq 10$ (which indicate a normal distribution)

### The test

**The Binomial Test** is used if we want to test an hypothesis about a population proportion (categorical data). The hypothesis testing process is the same as the for the One-Sample t-test:

1. **State hypothesis** (Null Hypothesis, Alternate Hypothesis)
2. **Use the Alternative Hypothesis to predict the characteristics the sample should have** (e.g. direction of change?) **including the ‘critical region’** (alpha level of significance)
3. **Obtain a sample from the population** and **calculate the sample statistic**
4. **Compare the sample data findings to the hypothesis to reach a conclusion**

![[Pasted image 20250407212031.png]]

![[Pasted image 20250407212040.png]]

![[Pasted image 20250407212049.png]]

### The $95\%$ confidence interval

Unfortunately SPSS **does not calculate the 95% confidence interval for the Binomial Test, but we can calculate it ourselves**

First, **we check if we would expect to see a normal distribution via the conditions $np \geq 10$ and $n(1-p) \geq 10$** . Then we can calculate the confidence interval:

$$
p = \left( \hat{p} - z \sqrt{\frac{\hat{p} \left(1 - \hat{p}\right)}{n}} , \ \hat{p} + z \sqrt{\frac{\hat{p} \left(1 - \hat{p}\right)}{n}}\right)
$$

where

- $\hat{p}$ is the **observed sample porprotion**
- $n$ is the sample size
- $z$ is the two-tailed critical value ($1.96$ for a $95\%$ confidence interval)

Also you can use this

![[Pasted image 20250407213951.png]]

### Example

> Suppose a drug company manufactures a new measles vaccine. The drug company claims that 30% of people aged between $18$ and $30$ years vaccinate against measles.
>
> However, other drug companies suspect this claim is false. They believe that a lower percentage of those aged between $18$ and $30$ years actually get vaccinated.

> $H_0:$ $30\%$ or more people aged between $18$ and $30$ years vaccinate
> $H_1$: Less than $30\%$ of people aged between $18$ and $30$ years vaccinate

![[Pasted image 20250408115644.png]]

Since $p < 0.05$, **we reject the Null Hypothesis**, and conclude the company's claim as Not True.

Before calculating the $95\%$ confidence interval, we check to see a normal distribution via the conditions:

$$
\begin{cases}
np \geq 10 \\
n(1 - p) \geq 10
\end{cases} \Rightarrow
\begin{cases}
40 \times 0.3 = 12 \geq 10 &\text{ok} \\
40 \times (1 - 0.3) = 28 \geq 10 &\text{ok}
\end{cases}
$$

Thus the distribution is normal, we can now calculate the $95\%$ confidence interval:

$$
\begin{matrix}
p = \left( \hat{p} - z \sqrt{\frac{\hat{p} \left(1 - \hat{p}\right)}{n}} , \ \hat{p} + z \sqrt{\frac{\hat{p} \left(1 - \hat{p}\right)}{n}}\right)
 \\~\\ = \left(0.15 - 1.96 \sqrt{\frac{0.15(1 - 0.15)}{40}}, \ 0.15 + 1.96 \sqrt{\frac{0.15(1 - 0.15)}{40}}\right) \\~\\
 = (0.0393, \ 0.2607)
\end{matrix}
$$

The $95\%$ confidence interval indicates that only between $3.93\%$ and $26.07\%$ of $18$ to $30$ year olds vaccinated against measles

### Writing a report

#### Example 1

> A researcher wanted to investigate the preferred use of Facebook in relation to adding content, or looking at other people’s content. Is there evidence to suggest that the percentage of young adults who prefer to post their own content differs to the percentage who prefer to look at other people’s content?

> $H_0$: Percentage of young adults who prefer posting their own content $= 50\%$ > $H_1$: Percentage of young adults who prefer posting their own content $\neq 50\%$

![[Pasted image 20250407225543.png]]

> It was hypothesised that less than 30% of 18 to 30 year olds get
> vaccinated against measles. In a random sample of forty 18 to 30 year olds, 15% reported having had a measles vaccination. This is lower than the 30% claimed by the drug company. A Binomial Test shows that this difference is significant, n=40, p=0.024. The 95% confidence
> interval indicates that between 4% and 26% of 18 to 30 year olds
> get vaccinated against measles. As expected, less than 30% of 18 to 30 year olds get vaccinated against measles.

#### Example 2

> It has been suggested that 11.0% of the general population are left-handed Goodman (2014) Is there evidence to suggest that the percentage of STA10003 students\* who are left handed is less than $11\%$?

> $H_0$: The percentage of students that are left handed is $11\%$ or more
> $H_1$ The percentage of students that are left handed is less than $11\%$

![[Pasted image 20250407221257.png]]

> It was hypothesised that less than 11.0% of STA10003 students
> are predominantly left-handed. In a random sample of $235$ STA10003 students, $8.5\%$ are left-handed. This is lower than for the general population $11.0\%$. A Binomial Test shows that this difference is not significant, $n=235, p=0.131$. The $95\%$ confidence interval indicates that between $4.9\%$ and $12.1\%$ of STA10003 students
> are left-handed. There is insufficient evidence to suggest that less than $11.0\%$ of STA10003 students are predominantly left-handed.

## Comparison between One-sample and Binomial t-test

(refer to [[#The Binomial test]] and [[#The One-Sample t-test]])

If we **want to test a hypothesis on population data, use the One-sample t-test**.

If we **want to test an hypothesis on a population proportion / categorical data, we use a Binomial test.**

Conceptually, **these tests are the same**, **we test our sample finding to a reference value in the population**

## Independent samples t-test

### Assumptions of the Independent sample t-test

- **Independence of observations:** any observation / score must be independent of any other
- **Populations must be normally distributed:** **both samples should come from normally distributed populations**. **If samples are large, normality is less of an issue**
- **Homogeneity of variances:** Both samples come from **populations with equal variances.**
  - We check if the **standard deviations $s$ differ**
  - If **one standard deviation is twice the other, we may have violated this assumption.**
  - We can **correct any difference with Levene's test.**

#### What if assumptions are violated?

The Independent Samples t-test **is robust to violation of the normality or equal variances provided that the group sides are approximately equal.**

But if the group sizes differ markedly (one group size $\approx 1.5$ times size of the other group) then **BOTH the normality and equal variances assumptions are violated, thus the test will NOT provide us with valid results. We need to use them carefully.**

### The test

The **independent samples t-test** is done on a metric $DV$ and 2 categories of a categorical $IV$ . We compare two samples / groups to see if they come from populations with different means.

Since the categorical $IV$ is different, the participants in the groups are different and unmatched.

- **Two-tailed hypothesis tests:** used when **testing a prediction that there is a difference, change, or effect without being specific on how it has changed.**
- **One-tailed hypothesis tests:** used when testing a prediction that there is an **increase / decrease, proving a direction for the change expected, but should only be used if highly confident on the direction of the prediction**

An independent-measures design **evaluates the mean difference between two populations / two treatment conditions.**

The **mean for the first population / group is $\mu_1$**
The **mean for the second population / group is $\mu_2$**

**The Null Hypothesis says there are no changes / no effects / no differences**. Thus it assumes $\mu_1 = \mu_2$ and we can state the Null Hypothesis:

$$
\begin{matrix}
H_0: \mu_1 - \mu_2 = 0 &\text{or}& H_0: \mu_1 = \mu_2 \\
H_1: \mu_1 - \mu_2 \neq 0 &\text{or}& H_1: \mu_1 \neq \mu_2
\end{matrix}
$$

We use the **difference between the two sample means to make an inference about the difference in the population.**

Independent measures t-test formula

$$
t = \frac{(M_1 - M_2) - (\mu_1 - \mu_2)}{s_{(M_1 - M_2)}}
$$

> [!Note] Note
> Due to the Null Hypothesis we can sometimes assume the population means are equal, so $\mu_1 - \mu_2 = 0$

| **t-statistic**                                   | **Sample data** | **Population <br>Parameter (hypothesized)** | **Sample Variance**                                                                |
| ------------------------------------------------- | --------------- | ------------------------------------------- | ---------------------------------------------------------------------------------- |
| Single Sample / One Sample t-test                 | $$M$$           | $$\mu$$                                     | $$s^2 = \frac{\text{SS}}{\text{df}}$$                                              |
| Independent Measures / Independent Samples t-test | $$M_1 - M_2$$   | $$\mu_1 - \mu_2$$                           | $$s_p^2 = \frac{\text{df}_1s_1^2 + \text{df}_2s_2^2}{\text{df}_1 + \text{df}_2} $$ |

Also since Obsidian doesn't have enough space, we write the last column down here

| **Estimated Standard Error**                                                 |
| ---------------------------------------------------------------------------- |
| $$s_M = \sqrt{\frac{s^2}{n}}$$                                               |
| $$s_{(M_1 - M_2)} = \sqrt{s_p^2\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}$$ |

The procedure goes as follows:

1. **State the Null Hypothesis and the Alternate Hypothesis**, and **choose an alpha level of significance. $(\alpha = 0.05)$**
2. **Need to have the degrees of freedom** to **use with the critical values table**
3. **Calculate statistics from the sample**
4. **From a conclusion**

### The $95\%$ confidence interval

The **$95\%$ confidence interval** which is the boundaries of where we believe the **true population mean difference** in
the independent sample t-test can be evaluated as:

$$
\mu_1 - \mu_2 = [M_1 - M_2 - t_\text{crit}s_{(M_1 - M_2)}, \ M_1 - M_2 + t_\text{crit}s_{(M_1 - M_2)}]
$$

### Example

> [!note] why
> one thing you're gonna notice a lot is that we do a lot of rounding for some reason, which is very annoying for a pure math lover like me

> In a doctor’s office, patients with high blood pressure are asked to participate in a study $n = 16$. Patients were randomly assigned to two groups. One group of patients are asked questions about sources of stress in their lives (emotional content) and then their blood pressure is measured (Talking Group) A second group of patients are asked to count aloud from 1 to 100 four times (physical effort) and then their blood pressure is measured (Counting Group)

> Talking group: $104, 110, 107, 112, 108, 103, 108, 118$, $n = 8, \ M = 108.75, \ s = 4.74$
> Counting group: $110, 96, 103, 98, 100, 109, 97, 105$, $n = 8, \ M = 102.25, \ s = 5.39$

Assume that there are no differences in population means (so the Null Hypothesis?) We calculate the t-statistic

$$
t = \frac{(M_1 - M_2) - (\mu_1 - \mu_2)}{s_{(M_1 - M_2)}}
$$

Top row:

$$
(M_1 - M_2) - (\mu_1 - \mu_2) = 108.75 - 102.25 - 0 = 6.5
$$

To evaluate the bottom row, we first calculate the **pooled sample variance $s_p^2$** :

$$
\begin{aligned}
s_p^2 = s_p^2 = \frac{\text{df}_1s_1^2 + \text{df}_2s_2^2}{\text{df}_1 + \text{df}_2} = \frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2 }{n_1 - 1 + n_2 -  1} \\~\\= \frac{(8 - 1) \times 4.74^2 + (8 - 1) \times 5.39^2 }{8 - 1 + 8 - 1} \approx  25.76
\end{aligned}
$$

Then we calculate \*\*the Estimated Standard Error $s_{(M_1 - M_2)}$

$$
s_{(M_1 - M_2)} = \sqrt{s_p^2\left(\frac{1}{n_1} + \frac{1}{n_2}\right)} = \sqrt{25.76 \left(\frac{1}{8} + \frac{1}{8}\right)} \approx 2.54
$$

And therefore we have

$$
t = \frac{(M_1 - M_2) - (\mu_1 - \mu_2)}{s_{(M_1 - M_2)}} = \frac{6.5}{2.54} = 2.559
$$

![[Pasted image 20250408084920.png]]

and since $t > 2.145$ , it lies in the critical region, thus we reject the Null Hypothesis and **conclude that there IS a difference between the 2 groups.**

The $95\%$ confidence interval is:

$$
\begin{matrix}
\mu_1 - \mu_2 = [M_1 - M_2 - t_\text{crit}s_{(M_1 - M_2)}, \ M_1 - M_2 + t_\text{crit}s_{(M_1 - M_2)}] \\~\\
= [108.75 - 102.25 - (2.145 \times 2.54), \ 108.75 - 102.25 + (2.145 \times 2.54)] \\~\\
= [1.05, \ 11.95]
\end{matrix}
$$

> The $95\%$ confidence interval indicates that the blood pressure level in the talking group is on average $1.05$ to $11.95$ levels higher than the counting group

### Independent Sample t-test via SPSS

We can produce the test via SPSS by the following procedure:

- **Analyze > Compare Means > Independent Samples t-test**
- **Transfer metric variable to Test Variable**
- **Transfer categorical variable to Grouping Variable**

We **need to define groups**, and **care should be taken to ensure that the groups are coded with the associated category codes. They can be coded error, but think carefully about how the output might look.**

![[Pasted image 20250408091517.png]]

To check for Equality of Variances, we compare Leve's p-value to $\alpha = 0.05$

![[Pasted image 20250408091611.png]]

### Writing a Report

When writing the report, note the following:

1. Set the scene (what do we hypothesize?)
2. **Sample findings for BOTH groups and comparison**
3. Interpret result (comparing p-value) and include $95\%$ confidence interval
4. Conclusion.

Remember:

> $p < 0.050$ => **SIGNIFICANT, Reject** $H_0$
> $p ≥ 0.050$ => **NOT SIGNIFICANT, Do Not Reject** $H_0$

#### Example 1

> In a doctor’s office, patients with high blood pressure are asked to participate in a study $(n = 16)$. Patients were randomly assigned to two groups.
>
> One group of patients are asked questions about sources of stress in their lives (emotional content) and then their blood pressure is measured (Talking Group).
>
> A second group of patients are asked to count aloud from 1 to 100 four times (physical effort) and then their blood pressure is measured (Counting Group)

> $H_0:$ the

![[Pasted image 20250408091517.png]]

![[Pasted image 20250408091611.png]]

> It was hypothesized that blood pressure measures differ for patients tested under different conditions. One group of parents were asked questions about scores of stress in their lives (emotional content) and their blood pressure was then measured (Talking Group) while the other group were asked to count aloud from 1 to 100 four times (physical effort) prior to their blood pressure being measured.
>
> In a sample of $16$ patients with high blood pressure, the average blood pressure measure for those in the Talking Group $(M = 108.75, \ s = 4.74, \ n = 8)$ was higher than for those in the Counting Group $(M = 102.25, \ s = 5.39, \ n = 8)$. An independent samples t-test shows that **this difference in average blood pressure measure is significant** $t(14) = 2.56, \ p = .023$
>
> The $95\%$ confidence interval indicates that on average, blood pressure measures for people assigned to a Talking Group is between $1.05$ and $11.95$ units higher than for people assigned to a Counting Group.
>
> As expected, blood pressure measures do differ for patients tested under different conditions.
>
> On average, blood pressure measures for patients assigned to a Talking Group are higher than for patients assigned to a Counting Group?

We also note the following:

- **Have assumptions been met?** (Independence, Normality, Homogeneity of Variances)
- Most of the report **relates to what we think** is happening, so be careful that the wording reflects this
  ![[Pasted image 20250408100639.png]]

#### Example 2

> It was hypothesized that, for STA10003 students,\* the average amount spent on take-away food per week differs for males and females.

Define $\mu_1$ as the mean take-away spending of male students, and $\mu_2$ as the mean take-away spending of female students

> $H_0: \mu_1 - \mu_2 = 0 \Leftrightarrow \mu_1 = \mu_2$
> $H_1: \mu_1 - \mu_2 \neq 0 \Leftrightarrow \mu_1 \neq \mu_2$

We check the assumptions:

![[Pasted image 20250408101357.png]]

> It was hypothesized that the amount spent on Take-away food per week differs for male and female STA10003 students.
>
> In a sample of $225$ STA10003 students, the average take-away food spend per week for males $(M = \$ 35.26, \ s = \$ 30.80, \ n = 104)$ was slightly higher than for females $(M = \$ 33.79, \ s = \$30.20, \ n = 121)$. An independent samples t-test shows that this **difference in the mean take-away food spend per week is NOT significant** $t(223) = 0.36, \ p = .719$
>
> The $95\%$ confidence interval indicates that on average, take-away food spend per week for male STA10003 students is between $\$6.57$ less and $\$9.50$ more than for female STA10003 students.
>
> There is insufficient evidence to suggest that the amount spent on Take-away food per week differs for male and female STA10003 students.

**Note: the study violates the assumption, since both samples are positively skewed (but test robust to violation)**

## Paired samples t-test

### Assumptions

The paired samples t-test is based on the following assumptions:

- **Independence of observations:** **The observations / scores in each condition are independent.**
- **Normality:** The **distribution of the difference scores in the population should be nomrally distributed**

Check the distribution of the **sample different scores** to see if they could come from a normally distributed population. If so, it is reasonable to expect that the population of difference scores is normally distributed.

> [!NOTE] Note
> We **do not check the Homogenity of variance** because the focus is on the difference scores rather than the actual scores.

### The test

(refer to [[#Research designs]] and [[#Independent, Dependent and Nuisance Variables]])

This test is a more sensitive research design than the **Independent Groups** because **rather than comparing the means of two unrelated groups, we are usually comparing the means for the sample people**. **The design is more sensitive as there is more control of nuisance variables. Because we have the same people, the background variables (participant nuisance variables?) remain the same.**

Using the same / carefully matched participants, we control the nuisance variables. The pair of scores are collected and the difference is measured.

#### Repeated Measures vs Matched Pairs

**Repeated Measures** uses the **same people** (thus control the participant nuisance variables) **looking to see if the "treatment" makes any difference**. **We are interested in the difference between the values / difference scores rather than the before / after values themselves**

### The $95\%$ confidence interval

The $95\%$ confidence interval can be calculated based on

$$
\mu_D = [M_d - t_\text{crit} s_{M_D}, \ M_d + t_\text{crit} s_{M_D}]
$$

### Example

> Does memory training help police officers remember more license plate numbers?
>
> A random sample of 15 police officers sat a license plate test. 10 different license plate numbers were projected on a screen for 5 seconds with a 15 second interval between projections. At the end of the projections, the police officers were asked to write down as many of the 10 license plate numbers (in any order) that they could remember.
>
> The police officers then undertook a week long memory training course.
>
> At the end of the memory training course, the police officers were retested (same conditions as the initial testing)

We measure the number of license plates remembered **before undertaking the memory training course and then the number of license plates remembered after undertaking the memory training course**. **We hypothesize that there is a difference in the number of license plates remembered.**

The difference $D$ can be defined as either $D = X_\text{after} - X_\text{before}$ or $X_\text{before} - X_\text{after}$

> [!my commentary] Note
> Either way, it doesn't really matter too much, since our Null and Alternate Hypothesis only state that the mean of $D$ equals zero, so we can switch them around, it doesn't matter much. But here, let's say we hypothesize that the number of license plates remembered is HIGHER after the memory training, so we take $D = X_\text{after} - X_\text{before}$ and the Null Hypothesis to be $\mu_D \leq 0$

Since our focus is on the difference scores, our hypotheses are:

> $H_0:$ $\mu_D \leq 0$ > $H_1:$ $\mu_D > 0$

![[Pasted image 20250408113049.png]]

The Paired samples t-test uses a similar logic to the [[#The One-Sample t-test]] but is based on the difference scores:

$$
t = \frac{M_D - \mu_D}{s_{M_D}}
$$

where

- $M_D$ is the **sample mean difference** ($D = \text{After} - \text{Before}$)
- $\mu_D$ is the **population mean difference**
- $s_{M_D}$ is the **estimated standard error of the difference**

$$
s_{M_D} = \frac{s_D}{\sqrt{n}}
$$

where

- $s_{M_D}$ is the **estimated standard error of the difference**
- $s_D$ is the **estimated standard error of the difference**
- $n$ is the **number of participants / matched pairs**

First, we need to calculate $s_D$ , we do this by calculating the **variance** and using the formula that $s_D = \sqrt{\text{variance}}$

![[Pasted image 20250408113958.png]]

Then

$$
s_{M_D} = \frac{s_D}{\sqrt{n}} = \frac{2.1995}{\sqrt{15}} \approx 0.568
$$

and

$$
t = \frac{M_d - \mu_D}{s_{M_D}} = \frac{1.533 - 0}{0.568} \approx 2.699
$$

![[Pasted image 20250408114229.png]]

Since $t > 2.145$, it lies in the critical region. Thus we **reject the Null Hypothesis**

> We conclude that there is a difference in the number of license plates remembered by the police after the memory training course.

We can also calculate the $95\%$ confidence interval:

$$
\begin{matrix}
\mu_D = [M_d - t_\text{crit}s_{M_D}, \ M_d + t_\text{crit}s_{M_D}] \\~\\
= [1.533 - 2.145 \times 0.568, \ 1.533 + 2.145 \times 0.568] \\~\\
= [0.315, \ 2.751]
\end{matrix}
$$

> The $95\%$ confidence interval indicates that the average number of license plates number remembered is between $0.32$ and $2.75$ after training

### Paired-samples t-test via SPSS

We use the **Transform > Compute Variable** procedure to calculate the difference scores, then we can use the **Analyze > Compare Means > Paired-Sample T-test** to perform a test.

![[Pasted image 20250408140907.png]]

Once again, we define the hypothesis

> $H_0:$ $\mu_D = 0$, there is no difference in the population mean scores
> $H_1:$ $\mu_D \neq 0$, there is a difference in the population mean scores.

![[Pasted image 20250408141023.png]]

- Before training: $M _\text{before}= 5.67, \ s_\text{before}=1.23$
- After training: $M_\text{after} = 7.20, \ s_\text{after} = 1.32$

Difference scores:

$$
\begin{matrix}
M_D = M_\text{after} - M_\text{before} = 1.53, \\~\\
s_D = 2.20
\end{matrix}
$$

> [!Note] Note
> yes you just can't subtract standard deviations

We then interpret the results. We have $t(14) = 2.70, \ p = .017$. Since $p < 0.05$, we **reject the Null Hypothesis, and conclude that there is a significant relationship that the scores are higher after training than before**

### Writing a report

#### Example 1: (based on the example above)

> It was hypothesized that there is a difference in the number of correctly identified license plate numbers police officers are able to identify after undertaking a memory training course than before undertaking the course.
>
> In a random sample of $15$ police officers, on average, the number of license plate numbers remembered after the memory training course was higher $(M = 7.20, \ s = 1.32)$ than the average number of license plate numbers remembered before undertaking the memory training course $(M = 5.67, \ s = 1.23)$
>
> A paired-samples t-test show that this difference in the average number of license plates remembered $(M_D = 1.53, \ s = 2.20)$ is significant, $t(14) = 2.70, \ p = .017$.
>
> The $95\%$ confidence interval indicates that the average number of license plate number remembered is between $0.32$ and $2.75$ higher after memory training than before training.
>
> As expected, there is a difference in the number of correctly identified license plate numbers police officers are able to identify after undertaking a memory training course than before undertaking the course. Police officers are able to correctly identify more license plate numbers after a memory training course than before undertaking the course.

#### Example 2

> Researchers believe that there is a difference in the self- estimated and actual height of boys. A random sample of 12 boys, aged between 12 and 16 years, were asked to self-estimate their height (in cm). The boys’ actual heights were then measured.

> $H_0: \mu_D= 0$: **No difference** in self-estimated and actual heights
> $H_0: \mu_D= 1$: **There is a difference** in self-estimated and actual heights

![[Pasted image 20250408150509.png]]

> Researchers hypothesized that there is a difference in the self- estimated and actual height of boys. In a random sample of 12 boys aged between 12 and 16 years, on average, the self estimated heights $(M=161.67\text{cm}, \ s=9.87\text{cm})$ were lower than their actual measured heights $(M=162.58\text{cm}, \ s=7.38\text{cm})$.
>
> A paired samples t - test shows that this difference in mean height $(M_D =0.92\text{cm}, \ s_D=5.12\text{cm})$ is not significant, $t(11)=0.62, \ p=.548$.
>
> The 95% confidence interval indicates that, on average, boys’ self-estimated heights are between $4.17\text{cm}$ less and $2.34\text{cm}$ more than their actual measured heights. There is insufficient evidence to suggest that there is a difference in the self-estimated and actual height of boys.

> [!Note] Commentary
> There are more examples but I cba

# Correlation, Relationships and Scatterplots

## Correlation

A **correlation is a relationship between two metric variables.** **Both variables are recorded and observed.** We **observe the patterns and trends in the data only:**

- **No manipulation of the $IV$ (observational research), see [[#Types of Research]]**
- **No cause and effect**

Since it is two metric variables, we have a **pair of numerical data from each participant.** We then **plot them on a scatterplot to give a picture of the relationship.**

A **scatterplot is useful to describe a relationship:** including its **direction, form, strength** , as well as the $DV$ and $IV$

- The $DV$ is plotted on the $Y$-axis, and the $IV$ is plotted on the $X$-axis.

> [!NOTE] Commentary
> So drawing like this somewhat gives a graphical form to the idea that the $DV$ is dependent on the $IV$ in some $y = f(x)$ way, at least if we don't bring in the nuisance variables.

Thus, **we can use a scatter plot to detect nonlinear relationships, subgroups and outliers.** **We can also use it to determine to detect if it's appropriate to use Pearson's Correlation Coefficient**

### Example

> We wish to explore the relationship between chocolate consumption and the level of happiness, with data coming in pairs of "happiness score" and the chocolate consumption per week in grams. We plot the $DV$ on the $Y$-axis and the $IV$ on the $X$-axis

![[Pasted image 20250408151801.png]]

![[Pasted image 20250408151810.png]]

## Relationship via scatterplots

A scatterplot **can be used to determine a relationship**, mainly three main attributes: **direction, form, and strength**

### Relationship forms

#### Linear Relationship

Linear Relationships is when the scatterplot points from a shape that looks similar to a line. **Linear Relationships have linear Form, and the direction depends on the slope of the line.** **If the slope / line go upwards, then the direction is positive. If the slope / line goes down, the direction is negative **

![[Pasted image 20250408152056.png]]

#### Curved Relationship

A **curved relationship** is **when the scatterplot points together form a shape that looks like a curve.**

![[Pasted image 20250408152326.png]]

> [!Note] IMPORTANT!
> **Pearson's $r$ will underestimate the strength in curved relationships!**

But if the relationship has no obvious curve, nor have any outliers, then you can still use Pearson's $r$ even though it look like... this

![[Pasted image 20250408232954.png]]

### Relationship strength

![[Pasted image 20250408152504.png]]

![[Pasted image 20250408152513.png]]

> [!Note] Commentary
> I have no idea what is happening, so I'm gonna assume my best guess, along with ChatGPT. So, essentially, what I assume is that, **a strength of a relationship is that when you tweak the $IV$, how does the $DV$ change? Does it cling to certain predictable pattern, likea graph, or are they just scattered all over the place? A strong relationship means that the data points follow a tight, well-defined pattern, the model explains most of the varation data. kinda it really**

### Outliers

![[Pasted image 20250408154731.png]]

> [!note] again
> **Univariate outliers** are **outliers in one variable at a time**. E.g. in the first graph, the outlier still fits in the range (bounded by $X$ coordinates) of the vertical lines, but they lie above the upper horizontal ($Y$-line) that bounds the rest of the data. **Bivariate outliers** are **outliers that doesn't fit in both variables. If you take each value independently and put them on the axis, they may look fine, but if you combine them, they cause a strange combination**

> [!Note] I have no idea what is happening so take this chart from ChatGPT

![[Pasted image 20250408155031.png]]![[Pasted image 20250408155104.png]]

### Relationship Sub-groups

![[Pasted image 20250408155647.png]]

### Always check the scatterplot

**Always check for Linearity, Subgroups, and Outliers.**

- If the scatterplot is **non-linear (curved), shows evidence of subgroups, or outliers, it is NOT appropriate to produce Pearson's Correlation**

![[Pasted image 20250408155820.png]]

## Pearson's $r$ correlation and related values

Pearson's $r$ **measures the strength of the linear relationship in a sample, on how closely the points cluster around the straight line. It has a value from $-1$ to $1$, with negative values indicating a negative direction**

### Pearson's $r$

#### Calculation of Pearson's $r$

To **calculate Pearson's $r$:**

$$
r = \frac{\text{SP}}{\sqrt{\text{SS}_x \times \text{SS}_y}}
$$

where

- $\text{SP}$ is the **Sum of Products (joint variability of the two variables)**
- $\text{SS}$ is the **Sum of squared deviations**

##### Sum of Products $\text{SP}$

To calculate the **Sum of Products $\text{SP}$ , we have two formulas that are usually equivalent:**

- **Definitional Formula:** use the deviations in the calculations $$\text{SP} = \sum (X - M_x)(Y - M_y)$$
- **Computational Formula:** use actual values $$\text{SP} = \sum XY - \frac{\sum X \sum Y}{n}$$

> [!Note] On sum of squared deviations
> Wait so the slides don't go into this, but **isn't the sum of squared deviations THE VARIANCE?**
> Don't you just love how they won't include actual info

Example:

![[Pasted image 20250408160858.png]]

![[Pasted image 20250408160916.png]]

Then we calculate the deviation scores:

![[Pasted image 20250408160950.png]]

![[Pasted image 20250408161118.png]]

#### Interpretation of Pearson's $r$

![[Pasted image 20250408160020.png]]

Calculating the strength **can use the scatterplot as a guide, or calculate Pearson's correlation coefficient $r$. **

To measure the strength (without direction, since we don't really need it) we take the absolute value $|r|$ first and compare it using this table

| Value in range   | Relationship strength |
| ---------------- | --------------------- |
| $0.50$ or more   | Strong                |
| $0.30$ to $0.49$ | Moderate              |
| $0.10$ to $0.29$ | Weak                  |
| Less than $0.10$ | Very weak             |

The value is **considered in terms of the strength of the linear relationship, not direction**

### Population correlation $\rho$

We state the Null and Alternate Hypothesis:

> $H_0: \rho = 0$, there is no relationship in the population
> $H_1: \rho \neq 0$, there is a relationship in the population

While \*\*Pearson's $r$ measures the strength of the linear relationship, we want to estimate the strength of the linear relationship in the population, $\rho$ .

** We can **use a $95\%$ confidence interval to describe the boundaries in-between which we believe the true population strength might lie. If calculating the $95\%$ confidence interval by hand, the sample scores must first be turned into [[#z-score]]s. You can also use online confidence interval calculators\*\*

![[Pasted image 20250408161505.png]]

### Co-efficient of determination $r^2$

While **Pearson's $r$ measures the strength of the linear relationship**, we **would also like to determine how much "importance" we can attach to the relationship.** That is, \*\*how much our variability in our dependent variable can be explained between our Dependent and Independent Variables

> For example, how much variability in number of Pies sold $(DV)$ can be explained by the linear relationship between Pies sold and Attendance figures at the games $(IV)$?

To calculate this, we the Pearson's $r$ calculated above ([[#Calculation of Pearson's $r$]]) and square it.

> e.g. previously we got the value of Pearson's $r = 0.875$, then we square it to get $r^2 = 0.7656$

We can now interpret this value that

> 76.6% of the variation in Number of Pies Sold (‘000s) $(DV)$ can be explained by the linear relationship between the Attendance figures $(IV)$ and Number of Pies Sold

## Pearson's $r$ hypothesis test

While **we have calculated Pearson's correlation co-efficient $r$ and determine the strength of the linear relationship, we should also check if there is an actual relationship between the two variables.**

We can **use Pearson's correlation critical values table to determine the value of the sample correlation $r$**

We can also calculate a t-statistic, an F-ratio, or use SPS.

![[Pasted image 20250408162534.png]]

> [!note] Important
> Pearson's $r$ must be **GREATER THAN OR EQUAL** to the value in the table to be significant.

### Writing a report

#### Example 1: the football example above

> It was suggested that at football matches with high attendance figures more pies would tend to be sold.
>
> In a random sample of 12 ALF football games, there was a strong, positive, linear relationship between attendance at games [‘000s] and pies sold [‘000s], and Pearson’s $r$ shows that this relationship is significant, $r=.88, \ n=12, \  p<.001$.
>
> The $95\%$ Confidence interval indicates that, in AFL games, the strength of the linear relationship is between $\rho =.60$ and $\rho =.96$ . As expected, at football matches with high attendance figures more pies do tend to be sold.

> Interpretation of $r^2$: $76.6\%$ of the variation in Pies Sales $(DV)$ can be explained by the linear relationship between Attendance Figures $(IV)$ and Pie Sales $(DV)$

#### Example 2: Chocolate happiness

![[Pasted image 20250408163044.png]]

![[Pasted image 20250408163054.png]]

> It was hypothesised that there is a relationship between Chocolate Consumption and Level of Happiness.
>
> In a random sample of 24 participants, there was a strong, negative linear relationship between Chocolate Consumption (grams per week) and Level of Happiness scores, and Pearson’s r shows that this relationship is significant, $r =- .99, \ n=24, \ p<.001$.
>
> The 95% Confidence interval indicates that, in the population, the strength of the linear relationship is between $\rho =- .97$ and $\rho =- .99$.
>
> As expected, there is a relationship between Chocolate Consumption and Level of Happiness scores. As the Level of Happiness increases the amount of Chocolate Consumed tends to decrease.

## Do we use paired-samples t-test or Pearson's $r$ ?

It depends on the question. **If you are comparing means, use a paired-sample t-test. If you are looking at a relationship, use Pearson's Correlation.**

> **Do people spend more time preparing meals than they do doing dishes?** => Comparing means [times] = **Paired samples t-test**
> **Do people who spend more time preparing meals also tend to spend more time doing dishes?**
> => Looking at a relationship = **Pearson’s correlation**

- Both the Paired-samples t-test and Pearson's $r$ correlation involve **two metric variables**
- In both cases, **the data is paired, but they answer different questions.**
- To **compare means, use the Paired-Sample t-test** (focus on the difference)
- To **identify relationships, use correlation**

## Nuisance Variables (continued)

See [[#Nuisance Variables and Confounding Factors]]

> There is a strong, positive linear relationship between ice-cream sales and the number of shark attacks.
>
> There is a moderate strength, linear relationship between the consumption of cheese and the consumption of chicken.

> [!Note] IMPORTANT
> **Just because there is a correlation between two variables, we CAN NOT assume that one is causing change in the other. CORRELATION IS NOT CAUSATION.** Other background variables can have an effect. **BE CAREFUL ABOUT MAKING ASSUMPTIONS. ONLY MAKE CAUSAL ASSUMPTIONS IF THE STUDY IS EXPERIMENTAL, NOT OBSERVATIONAL**

# Linear Regression

## Some old concepts

- **Pearson's Correlation Coefficient $r$** measures the **strength of the linear relationship** in the sample
- **$95\%$ confidence interval for Pearson's $r$ ($\rho$)** measures the **strength of the linear relationship in the population**
- **The coefficient of determination $r^2$** measures **how much variability in the $DV$ can be explained by the linear relationship between the $DV$ and the $IV$. It gives an indication of the "importance" of the $IV$ when predicting the $DV$**

## Linear Regression - Equation

The **Linear Regression Equation** is the line of best fit to the existing data. It allows **describing the relationship more than just stating that one exists,** and **can be used to predict the value of the $DV$ if the $IV$ is known.**

The equation has the following form:

$$
Y = bX + a
$$

where

- $Y$ is the **Dependent Variable Value** ($DV$ Value)
- $b$ is the **slope** (or **regression co-efficient**)
- $X$ is the **Independent Variable Value** ($IV$ value)
- $a$ is the **Y-intercept** (vertical intercept / constant)

## Example

If we want to make a prediction about costs of moving a house based on time taken to move and we have:

- Removalist A charges $\$500$ regardless of time taken
- Removalist B charges $\$100$ per hour
- Removalist C charges $\$70$ for a starting fee plus an additional $\$80$ per hour.

What is the predicted costs of all the removalists if time taken is predicted to be $4$ hours?

We use the linear equation $$\text{Price} = b \times \text{Time} + a$$
where our time will be substituted with $4$ hours.

| Removalist | $a$  | $b$   | Price in 4 hours ($4a + b$)    |
| ---------- | ---- | ----- | ------------------------------ |
| A          | $0$  | $500$ | $\$500$                        |
| B          | 100  | 0     | $4 \times \$100 = \$400$       |
| C          | $80$ | $70$  | $4 \times \$80 + \$70 = \$390$ |

![[Pasted image 20250408171825.png]]

## Errors and the Least-Square Solution

### Errors

But **when we make predictions, there are almost always going to be errors.**

**Sometimes we overestimate, sometimes we underestimate**. The distance between **the data point** and **the plotted line-of-best-fit are called residuals (prediction errors).** The line-of-best-fit should keep the prediction errors / residuals **as small as possible.** Thus, we use the **Least-Squares solution** to form a line.

### Least-Squares solution

We define **the distance / error between the predicted value (in this case, the line) and the actual value.**

For a prediction $\hat{Y}$ for a value with actual value $Y$, we define the distance:

$$
\text{Distance} = Y - \hat{Y}
$$

Some of the errors will therefore be positive, others may be negative. **Similar to deviation, all positive and negative values should add to zero. Thus, we use squares to determine the total error:**

$$
\text{Total squared error} = \sum \left(Y - \hat{Y}\right)^2
$$

for all values $Y$ and its respective prediction $\hat{Y}$ .

The **line of best fit should keep the prediction errors as small as possible.**

We can only make predictions about the $\hat{Y}$ predicted value within the boundaries of the $X$ value boundaries. The values are unknown outside of these boundaries.

We can also standardize to simplify the regression equation

$$
\hat{z}_y = rz_x
$$

where

- $\hat{z}_y$ is the **predicted z-score of $Y$**
- $r$ is the **(Pearson's correlation coefficient $r$ )**
- $z_x$ is the **z-score for $X$ values**

## Calculation of the slope and intercept

We can calculate the $b$ and $a$ coefficient in the [[#Linear Regression - Equation]] above. First, we evaluate $b$ :

$$
b = \frac{\text{SP}}{\text{SS}_x} = r\frac{s_Y}{s_X}
$$

where

- $\text{SP}$ is the **[[#Sum of Products $text{SP}$]]**
- $\text{SS}_X$ is the **Sum of squared deviations of X values**
- $r$ is **Pearson's correlation coefficient $r$**
- $s_Y$ is the **standard deviation for $Y$ values**
- $s_X$ is the **standard deviation for $X$ values**

After obtaining $b$, we calculate the value of $a$ :

$$
a = M_Y - bM_X
$$

where

- $a$ is the **Y-intercept**
- $M_Y$ is the **Mean of $Y$ values**
- $M_X$ is the **Mean of $X$ values**
- $b$ is the **regression co-efficient / slope**

### Example

![[Pasted image 20250408173315.png]]

![[Pasted image 20250408173332.png]]
![[Pasted image 20250408173502.png]]
![[Pasted image 20250408173736.png]]

### Interpretation of the Slope, Intercept and Equation.

The slope $b$ calculated above can be understood that **for each $1$ increase in the $IV$, on average, the $DV$ goes up $b$ more**

> e.g. for the above: **each additional person increases the number of pies sold by $0.418$** . Each additional $1000$ people visited makes the number of pies sold $418$ more.

The intercept tells us that for the value $X = 0$ we would have a prediction $\hat{Y} = a$ .

Thus, the equation can be interpreted as a prediction of the relations.

![[Pasted image 20250408182149.png]]

## Prediction Errors

While we can use the equation $\hat{Y} = bX + a$ above to predict the value of $Y$ given $X$, **we need to determine the accuracy of the prediction. To measure the accuracy, we would need to calculate a standard error of estimate. A measure of the standard distance between the predicted $Y$ values per the regression line and the actual $Y$ values in the data.**

The **standard error of the estimate is similar to a standard deviation.**

$$
\text{Standard Error of Estimate} = \sqrt{\frac{\text{SS}_\text{residual}}{\text{df}}} = \sqrt{\frac{\text{SS}_\text{residual}}{\text{n - 2}}}
$$

> [!Note] IMPORTANT
> Unlike the other cases, $\text{df}$ here is $n - 2$ and NOT $n - 1$! This is because we have 2 values ($X$ and $Y$) to calculate on the regression line, we place 2 restrictions on the variability

Thus, we need to calculate

$$
\text{SS}_\text{residual} = \sum \left(Y - \hat{Y}\right)^2
$$

Therefore, it is based on the remaining distance between the actual $Y$ values and the predicted $\hat{Y}$ values.

### Example

![[Pasted image 20250408184210.png]]

![[Pasted image 20250408184224.png]]

### Relationship between the standard error and the correlation.

- If the **data points are close to the line of best fit, the standard error of the estimate should be small.**
- The **standard error of the estimate will be larger if the data points are more spread out as there is increased variability (and more possible error)**

The **co-efficient of determination $r^2$** is the **proportion of variability predicted by the linear relationship between $X$ scores and $Y$ scores.**

We can use **the equation of $(1-r^2)$ to measure the UNPREDICTED proportion of variability.**

We have

$$
\text{SS}_\text{redisual} = \left(1-r^2\right) \text{SS}_y
$$

and so we can rewrite the **standard error of estimate** as:

$$
\text{Standard Error of Estimate}
$$

$$ = \sqrt{\frac{\text{SS}_\text{residual}}{\text{df}}} = \sqrt{\frac{\text{SS}_\text{residual}}{\text{n - 2}}}$$

$$
\\~\\= \sqrt{\frac{\left(1-r^2\right) \text{SS}_y }{\text{df}}} = \sqrt{\frac{\left(1-r^2\right) \text{SS}_y }{\text{n - 2}}}
$$

> [!Note] about Latex
> Yes I have to print this out into 3 latexes just so that it is barely visible. The joy.

**The standard distance between the actual data point and regression line is measured by the standard error of estimate**

![[Pasted image 20250408185147.png]]

![[Pasted image 20250408185237.png]]

## Linear Regression via SPSS

**To produce the regression analysis in SPSS:**

- **Analyze > Regression > Linear**
- **Transfer the $DV$ into the Dependent Section and $IV$ into the Independent section**
- **Can request the $95\%$ confidence interval for the slope**

![[Pasted image 20250408185304.png]]

![[Pasted image 20250408185321.png]]

![[Pasted image 20250408185337.png]]

### A specific case study?

![[Pasted image 20250408185353.png]]

### Writing a report

When writing a report, include the following:

1. **Always produce a scatterplot first. Check for linearity, outliers, subgroups, etc**
2. **Produce Pearson's correlation coefficient $r$ and the co-efficient of determination $r^2$ **
3. **Produce Regression Equation**
4. **Include Slope of Regression Line if the relationship is significant and make sense.**
5. **If applicable, include the $95\%$ confident interval, and $r^2$**

> Introduction, including the alternative hypothesis for the study => Sample size and description of the relationship (direction, form, strength) =>
> Comment as to whether the results are significant or not significant – quoting appropriate statistics =>
> An interpretation of the 95% confidence interval for the correlation - quoting relevant values =>
> An interpretation of the slope if appropriate (if significant finding for correlation =>
> Conclusion which relates back to the alternative hypothesis

While not included in the actual reports, the interpretation of the coefficient of determination $r^2$ and the interpretation of the $95\%$ confidence interval are important to acquire:

- **Interpretation of $r^2$:** [$r^2$ as percentage] of the variation in $Y$ can be explained by the linear relationship between $X$ and $Y$
- **Interpretation of $95\%$ confidence interval:** In the population the sample was drawn from, for each additional $1$ added to $X$ , on average, the $Y$ is between [the two bounds of the interval] higher/lower

#### Example 1: Fitness.... thing?

> [!Note] Commentary
> Good luck figuring out what the question is.

![[Pasted image 20250408191009.png]]

> It was hypothesised that as hours of training per week increase, the physical fitness score also tends to increase.
>
> In a random sample of 25 Gym members, there was a strong positive, linear relationship between the number of hours of training per week and fitness scores, and Pearson’s $r$ shows that this relationship is significant $(r = .78, \ n = 25, \ p < .001)$.
>
> The $95\%$ confidence interval for Pearson’s correlation indicates that the strength of the relationship is between $\rho = .56$ and $\rho = .90$.
>
> In the sample, for each additional hour spent training per week, on average, the physical fitness score was $.17$ points higher.
>
> As expected, as hours of training per week increase, the physical fitness score also tends to increase.

### Example 2: Chocolate consumption and happiness

![[Pasted image 20250408194131.png]]

> It was hypothesized that there is a relationship between Chocolate consumption and Level of Happiness.
>
> In a random sample of 24 participants, there was a strong, negative linear relationship between Chocolate consumption (gm per week) and Level of Happiness scores, and Pearson’s $r$ shows that this relationship is significant, $r = - .99, \ n = 24, \ p < .001$.
>
> The 95% Confidence interval indicates that, in the population, the strength of the linear relationship is between $\rho = - .97$ and $\rho = - .99$.
>
> In the sample, for each additional happiness score, on average, chocolate consumption is 12.00gm per week less. As expected, there is a relationship between Chocolate consumption and Level of Happiness. The higher the happiness score, the lower the chocolate consumption (grams per week) tends to be.
>
> The 95% confidence interval indicates that in the population for each additional happiness score, on average, chocolate consumption is between $11.15$ grams and $12.85$ grams per week less.

# Parametric and Non-Parametric tests

## Comparison

The **parametric tests uses numerical scores and make assumptions on population parameters**, such as **the mean and normality of population distributions.** The **non-parametric tests** operates on **categories, frequencies and percentages, and make no assumption on normality or distribution.**

The reason we use Non-parametric tests is that **numerical score may violate assumptions, and the level of variance can be high.** Thus, we can convert numbers to groups, which eliminates variance, and sometimes, just is more convenient.

## Chi-Square Goodness of Fit $\chi^2$

The **chi-square goodness of fit $\chi^2$ uses sample data to determine how well the sample proportions "fit" the population proportions based on the Null Hypothesis:**

> $H_0:$ The proportions are equal, no difference / preference.
> $H_1:$ The proportions are different, there's a preference.

or

> $H_0$: There is no difference in the population populations.
> $H_1:$ There is a difference in the population proportions.

### Expected Frequency

The **expected frequency** is the frequency we hypothesize if the sample was a "good fit" of the Null Hypothesis

The Expected Frequency can be calculated via:

$$
f_e = pn
$$

where

- $f_e$ is the **expected frequency**
- $p$ is the **expected proportion**
- $n$ is the **sample size**

Thus we gained another formula:

$$
\sum f_e = n
$$

### Calculation of the Chi-Square

The chi-square **measures how well the observed frequency $f_o$ fit with the expected frequency $f_e$**

> [!Note] typo alert
> Also, the slides has a typo, it should be $f_e$ instead of $f_E$. According to our lord and savior ChatGPT they share the same meaning.

$$
\chi^2 = \sum \frac{(f_o - f_e)^2}{f_e}
$$

Diving by $f_e$ allows us to ascertain if we have a large or small discrepancy. Large discrepancy => Large $\chi^2$ , Small discrepancy => Small $\chi^2$ .

#### Example calculation

![[Pasted image 20250408200812.png]]

![[Pasted image 20250408200822.png]]

### The $\chi^2$ distribution

The $\chi^2$ distribution is a **theoretical distribution based on all random samples when the Null Hypothesis is true** . We **use the distribution to decide how large or small our critical value of $\chi^2$ is (that is when to reject the Null Hypothesis)**

In the $\chi^2$ distribution:

- **All $\chi^2$ values are positive**
- The shape of the distribution is **positively skewed**
- The **number of categories $C$** will also **determine the shape of the distribution.** Since we're adding values for each category, the **more categories we have, the larger we expect $\chi^2$ to be**
- The distribution is based on the **degrees of freedom $\text{df}$**

And also

$$
\text{df} = C - 1
$$

![[Pasted image 20250408200746.png]]

### $\chi^2$ statistic of Independence

The chi-squared $\chi^2$ test of independence is a **test to determine whether a relationship exists between two categorical variables**. It is based on **sample information, frequency distribution matrix**. **It can only conclude a result of a relationship, NO casual conclusions.**

We state the Null and Alternate Hypothesis:

> $H_0:$ There is **NO** relationship between $X$ and $Y$
> $H_1:$ There **IS** a relationship between $X$ and $Y$

First, we use a formula to evaluate the [[#Expected Frequency]] above:

$$
f_e = \frac{f_c f_r}{n}
$$

where

- $f_e$ is the **Expected Frequency**
- $f_c$ is the **Column Frequency**
- $f_r$ is the **Row Frequency**
- $n$ is the **sample size.**

Again we will need the Degrees of Freedom:

$$
\text{df} = (R - 1)(C - 1)
$$

where

- $\text{df}$ is the **degree of freedom**
- $R$ is the number of rows
- $C$ is the number of columns

#### Example:

![[Pasted image 20250408202245.png]]

> [!Note] Commentary
> So for the $\chi^2$ distribution, $H_0$ is the fact that there is **NO** relationship between variables, and $H_1$ is the fact that there is a relationship between variables.

![[Pasted image 20250408202252.png]]

> [!note] Commentary
> Really useful to understand how those $f_e$ above (those 2 instances) got calculated. So, the idea is that, there are 2 categories each. One for gender, one for animal. And the $f_c$ and $f_e$ is essentially the frequencies that are there for the formula to work, so what do you do? You take the **total frequency** of each category (so e.g. for males with dogs we have $f_c = 50$ dogs, $f_r=100$ males and $n = 150$ samples)

![[Pasted image 20250408202345.png]]

> [!Note] Commentary
> Here we just use the normal frequencies in that table, so like the $f_o$ and $f_e$ here are just compared to that table. Also the numbers are round because we're talking about humans

![[Pasted image 20250408202357.png]]

> ![Note] Commentary
> I guess this is because we stopped rounding so the $\chi^2$ changes?

![[Pasted image 20250408205640.png]]

> [!Note] Commentary
> I really need to go for something here, so we know that $\chi^2$ doesn't lie in the critical region so we don't reject $H_0$, BUT there's an idea that the critical region of $\chi^2$ is going to start from $0$ because it is non-negative. Even the graph reflected that, it started from $0$.

### Writing a report

The report for a Chi-square analysis should include:

1. **Introduction, including the alternative hypothesis for**
   **the study**
2. **Sample information** including **Size / Overview**
3. **Sample statistics (percentages) if we have evidence of a**
   **relationship**
4. Comment as to **whether the results are significant or**
   **not significant – quoting appropriate statistics**
5. **Conclusion which relates back to the alternative**
   **hypothesis**

> [!Note] Important!
> **REQUEST COLUMN PERCENTAGES, NOT ROW PERCENTAGES**

#### Example 1: the dog example above

![[Pasted image 20250408210931.png]]![[Pasted image 20250408210945.png]]

![[Pasted image 20250408211030.png]]

> It was hypothesised that males are more likely than females to prefer dogs as pets.
>
> In a sample of 150 adults males were less likely than females to prefer dogs as pets. A Chi-square test revealed no significant relationship between gender and type of pet preferred $\chi^2_{(1)}=1.50, \ p=.221$.
>
> There is insufficient evidence to suggest that males are more likely than females to prefer dogs as pets.

#### Example 2

> It was hypothesised that males are more likely than females to be left-handed. We surveyed Foundations of Statistics students and recorded their Predominant Handedness as well as their Gender.
>
> a.What are the two variables and how are they measured (metric or categorical)? **Predominant Handedness - categorical** and **Gender - categorical**
> b. Which groups are being compared? **The Gender Groups**
> c. Which is the independent variable? **The Gender level**

![[Pasted image 20250408214041.png]]

![[Pasted image 20250408214123.png]]

> [!Note] Commentary
> In fact, for the SPSS stuff, just look at the p-value and compare it to $0.05$. So the result for that one above is "no".

> It was hypothesized that males are more likely than females to be left-handed.
>
> In a sample of 232 Foundations of Statistics students males were less likely than females to be left-handed.
>
> A Chi-square test revealed no significant relationship between gender and predominant handedness $\chi^2_{(1)}= 0.33, p = .566$.
>
> There is insufficient evidence to suggest that males are more likely than females to be left-handed.

# Relative Risk and Odds Ratios

## Basic risks and odds

The **risk of an event $A$ occuring** is the probability that the event occurs. Therefore we can write

$$
\text{Risk}(A) = \frac{\text{Number of outcomes classified as $A$}}{\text{Total number of outcomes}} = \text{Probability of $A$}
$$

The **odds of an outcome $A$ occuring** is the **ratio of the number of outcomes classified as $A$ to the number of outcomes classified as $\overline{A}$ (opposite of A)**. We can then rewrite:

$$
\text{Odd}(A) = \frac{\text{Number of outcomes classified as $A$}}{\text{Number of outcomes classified as $\overline{A}$ (or number of outcomes NOT classified as $A$) }}
$$

Or more compactly

$$
\text{Odd}(A) = \frac{\text{Risk}(A)}{\text{Risk}(\overline{A})} = \frac{P(A)}{P(\overline{A})}
$$

## Relative Risk

### Calculation

We can then define the **relative risk that an event occurs for people classified into a particular group:**

$$
\text{RR} = \frac{\text{Risk that event occurs for people in the group}}{\text{Risk that event occurs for people NOT in the group}}
$$

And a special case: the **relative risk that an event occurs for people who take part in an intervention program is:**

$$
\text{RR} = \frac{\text{Risk that event occurs for people who take part in the intervention}}{\text{Risk that event occurs for people who did not take part in the intervention}}
$$

### Interpretation

**Does the intervention reduce / increase the risk of occurence?**

We look at the relative risk ratio of an event occurring for people who take part in the intervention.

- $\text{RR} = 1$ indicates that **the risk of the event occurring is the same whether or not the people take part in the intervention**
- $\text{RR} < 1$ means that the **risk of the event occurring is reduced for people who take part in the intervention**
- $\text{RR} > 1$ means that the **risk of the event occurring is increased for people who take part in the intervention**

### Example

> [!note] Commentary
> Yes this is really hard to warp my mind around

![[Pasted image 20250408221112.png]]

> [!note] Commentary
> Ok so, we look at the case above, where the intervention program is being vaccinated. So, we evaluate the risk for people who took part in the intervention / risk for people who didn't take part. The risk for the vaccinated people is the probability that a vaccinated person got the flu, so that's $\frac{18}{128}$, and similarly the risk for the unvaccinated people is $\frac{57}{72}$. So we take $RR = \frac{18}{128} / \frac{57}{72}$, that's the risk.

=> **This means that people taking part in an intervention is $\text{RR}$ times as likely to have the event occurring to them as people NOT taking part in the intervention**

## Odd Ratio

### Calculation

Equivalently, we also define the **odd ratio that an event occurs for people classified into a particular group:**

$$
\text{OR} = \frac{\text{Odds that the event occurs for people in the group}}{\text{Odds that the event occurs for people NOT in the group}}
$$

And the **Odd Ratio in relation to an event occuring for people who take part in an intervention program:**

$$
\text{OR} = \frac{\text{Odds that the event occurs for the people who take part in the intervention}}{\text{Odds that the event occurs for the people who DID NOT take part in the intervention}}
$$

### Interpretation

- $\text{OR} = 1$ means **the outcome is the same in both groups**
- $\text{OR} < 1$ means **the intervention is better than the control**
- $\text{OR} > 1$ means **the control is better than in the intervention**

> [!note] Note
> Here the "control" **refers to NOT taking part in the intervention**, and the "intervention" **refers to taking part in the intervention**. So you could define **"control group" as the group NOT taking part in the intervention** and **"intervention group" as the group taking part in the intervention**. Finally I knew where those terms come from.

### Example

![[Pasted image 20250408222720.png]]

> [!Note] Commentary
> Similar to the [[#Relative Risk]] section I'm gonna provide a commentary here. So, the intervention here is the vaccination, and we consider that it is the ratio of odds if you get vaccinated vs if you don't. So if you get vaccinated, the ratio is the probability of you getting a flu to the probability that you don't $(A / \overline{A})$ so it's $\frac{18}{110}$. Similarly, if you're not vaccinated, the ratio is the probability that you get a flu on the probability that you don't, so that's $57/15$. Then, you combine these odds to reach the result in the slide.

=> **In the sample, this means that people taking part in an intervention is $\text{OR}$ the odds of having the event occurring to them as people NOT taking part in the intervention**

## Calculation of $RR$ and $OR$ via our sponsor ChatGPT

![[Pasted image 20250408224826.png]]

![[Pasted image 20250408224838.png]]

## $\text{RR}$ and $\text{OR}$ in SPSS

We use **Analyze > Descriptive Statistics Crosstabs** procedure in SPSS.

- **DV in the columns**
- **IV in the rows**
- **Cells: Request "row percentages"**
- **Statistics: Request "Risk"**
  ![[Pasted image 20250408225646.png]]

![[Pasted image 20250408225705.png]]

![[Pasted image 20250408225725.png]]

![[Pasted image 20250408225741.png]]
